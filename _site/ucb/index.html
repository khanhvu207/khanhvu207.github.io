<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>The upper confidence bound algorithm - EntropyMaxxing</title>
<meta name="description" content="Bandits are a class of reinforcement learning (RL) problems where a learner has to choose between different actions, each of which has an unknown reward. The key difference between bandits and RL problems is that in bandits, there is an absence of states or transition between states. Through interaction with the environment, the learner learns the reward distribution of each action and tries to maximize its cumulative reward.">


  <meta name="author" content="Khánh Vũ">
  
  <meta property="article:author" content="Khánh Vũ">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="EntropyMaxxing">
<meta property="og:title" content="The upper confidence bound algorithm">
<meta property="og:url" content="http://localhost:4000/ucb/">


  <meta property="og:description" content="Bandits are a class of reinforcement learning (RL) problems where a learner has to choose between different actions, each of which has an unknown reward. The key difference between bandits and RL problems is that in bandits, there is an absence of states or transition between states. Through interaction with the environment, the learner learns the reward distribution of each action and tries to maximize its cumulative reward.">







  <meta property="article:published_time" content="2025-02-03T00:00:00+01:00">





  

  


<link rel="canonical" href="http://localhost:4000/ucb/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Khánh Vũ",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="EntropyMaxxing Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- for mathjax support -->
<!-- 
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js", "AMSmath.js", "AMSsymbols.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  </script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
 -->

<!-- for mathjax support -->

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js", "AMSmath.js", "AMSsymbols.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] },
      TeX: {
        Macros: {
        }
      }
    });
  </script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js"></script>


<!-- Theme stylesheets: light and dark -->
<link id="light-theme-css" rel="stylesheet" href="/assets/css/main.css" media="all">
<link id="dark-theme-css" rel="stylesheet" href="/assets/css/dark.css" media="not all">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>


<script>
  (function() {
    var lightLink = document.getElementById('light-theme-css');
    var darkLink = document.getElementById('dark-theme-css');
    function applyTheme(theme) {
      if (theme === 'dark') {
        lightLink.media = 'not all';
        darkLink.media = 'all';
      } else {
        lightLink.media = 'all';
        darkLink.media = 'not all';
      }
    }
    // Initialize theme based on saved preference
    applyTheme(localStorage.getItem('theme'));
    document.addEventListener('DOMContentLoaded', function() {
      var btn = document.getElementById('theme-toggle');
      if (!btn) return;
      function updateIcon() {
        if (darkLink.media === 'all') {
          btn.innerHTML = '<i class="fas fa-sun"></i>';
        } else {
          btn.innerHTML = '<i class="fas fa-moon"></i>';
        }
      }
      btn.addEventListener('click', function() {
        var darkMode = (darkLink.media === 'all');
        var newTheme = darkMode ? 'light' : 'dark';
        // Save preference, then reload to apply cleanly
        localStorage.setItem('theme', newTheme);
        location.reload();
      });
      updateIcon();
    });
  })();
</script>

    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--posts">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          EntropyMaxxing
          
        </a>
        <!-- <div class="cute-gif"> -->
          <!-- <img src="../assets/images/penguin.gif" style="width: 25%; display: inline-block;" alt="cute gif"> -->
        <!-- </div> -->
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li></ul>
        
        <button id="theme-toggle" class="search__toggle" type="button" aria-label="Toggle dark mode">
          <i class="fas fa-moon"></i>
        </button>
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/avatar.png" alt="Khánh Vũ" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">Khánh Vũ</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>i’m just a chill guy :)</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <div class="archive">
    
      <h1 id="page-title" class="page__title">The upper confidence bound algorithm</h1>
    
    <!-- ## A primer on bandits -->
<p>Bandits are a class of reinforcement learning (RL) problems where a learner has to choose between different actions, each of which has an unknown reward.
The key difference between bandits and RL problems is that in bandits, there is an absence of states or transition between states.
Through interaction with the environment, the learner learns the reward distribution of each action and tries to maximize its cumulative reward.</p>

<p>In this blog post, we will discuss the upper confidence bound (UCB) algorithm, which is a popular algorithm for solving bandit problems.</p>

<h2 id="a-primer-on-stochastic-bandits-lattimore-and-szepesvári-2020">A primer on stochastic bandits (Lattimore and Szepesvári, 2020)</h2>

<p>A stochastic bandit is a collection of distributions \(\nu = \{P_a : a\in \mathcal{A} \}\) in which:</p>

<ul>
  <li>The learner interacts with the environment for $n$ rounds. We call $n$ the time horizon.</li>
  <li>At each round $t$, the learner selects an action \(A_t \in \mathcal{A}\) and receives a reward \(X_t \sim P_{A_t}\).
In this blog post, we assume that \(X_t\) is a \(1\)-sub-Gaussian random variable with mean \(\mu_a := \mathbb{E}[X | A = a]\) and variance of at most \(1\).</li>
  <li>The sequence of outcomes is denoted by \(A_1, X_1, A_2, X_2, \ldots, A_n, X_n\).</li>
</ul>

<p>In additional, it has to satisfy two statistical assumptions:</p>

<ol>
  <li>The conditional distribution $X_t$ given $A_1, X_1, \ldots, A_{t-1}, X_{t-1}, A_t$ is \(P_{A_t}\), capturing the fact that the environment samples rewards from the distribution corresponding to the action selected by the learner.</li>
  <li>The conditional law of action $A_t$ given $A_1, X_1, \ldots, A_{t-1}, X_{t-1}$ is \(\pi_t(\cdot \mid A_1, X_1, \ldots, A_{t-1}, X_{t-1})\), where $\pi_t$ is a probability distribution over the action space $\mathcal{A}$.
The learner is thus characterized by the sequence of probability distributions $\pi_1, \pi_2, \ldots, \pi_n$.
Importantly, the assumption here is that the learner cannot use the future to make decisions.</li>
</ol>

<p>The usual metric to evaluate the performance of the learner is the <em>expected regret</em>, which is defined as the difference between the cumulative reward of the optimal policy and the cumulative reward of the learner:</p>

\[\begin{align}
R_n := n \mu^* - \mathbb{E}\left[\sum_{t=1}^n X_t\right]
\end{align}\]

<p>where \(\mu^* := \max_{a\in \mathcal{A}} \mu_a\) is the mean of the optimal action.</p>

<p>From the above formulation, the optimal policy is indeed the one that selects the action with the highest expected reward at each round.
The goal of the learner is to <em>minimize the expected regret</em> by devising a good policy.
It is worth emphasizing that this is not an optimization problem; the learner does not know the reward distributions \(\nu\) and has to learn them through interaction with the environment.</p>

<h2 id="the-ucb-algorithm">The UCB algorithm</h2>

<p>The crux of this algorithm relies on the <em>optimism principle</em>, which states that the learner should be optimistic about the reward of each action.
Why is this a good idea?
We shall see that this philosophy leads to a good balance between exploration and exploitation.</p>

<p>In particular, the UCB algorithm maintains an upper confidence bound for each action, denoted by \(\text{UCB}_a(t-1)\).
At each round, the learner selects the action with the highest UCB and receives the corresponding reward.
Concretely, we have the following steps for every round \(t=1,2,\ldots,n\):</p>

<ol>
  <li>Select action \(A_t = \underset{a\in \mathcal{A}}{\text{argmax}}~\text{UCB}_a(t-1)\).</li>
  <li>Observe reward \(X_t \sim P_{A_t}\).</li>
</ol>

<p>What should we choose as the UCB?
By the optimism principle, \(\text{UCB}_a(t-1)\) should be an overestimate of \(\mu_a := \mathbb{E}[X | A = a]\) and should converge to it as the number of rounds increases.
Specifically, we define the UCB as follows:</p>

\[\begin{align}
\text{UCB}_a(t-1, \delta) = \hat{\mu}_a(t-1) + \color{darkred}{\underbrace{\sqrt{\frac{2\log(1/\delta)}{T_a(t-1)}}}_{\text{Exploration bonus}}} \tag{1} \label{eq:ucb}
\end{align}\]

<p>where \(T_a(t-1)\) is the number of times action \(a\) has been selected up to round \(t-1\) and \(\delta\) is a confidence parameter.
The term \(\hat{\mu}_a(t-1)\) is the empirical mean of the rewards of action \(a\) up to round \(t-1\):</p>

\[\begin{align}
\hat{\mu}_a(t-1) := \frac{1}{T_a(t-1)}\sum_{s=1}^{t-1} \mathbb{I}(A_s = a)X_s,
\end{align}\]

<p>One small remark is that this choice of UCB is not unique; there are other ways to define the UCB.
In essence, this form of UCB in Eq. \(\ref{eq:ucb}\) is almost an inverse of the <a href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality">Hoeffding inequality</a> with one caveat that the count \(T_a(t-1)\) in the denominator is a random variable as well.
We can think of the term \(\sqrt{\frac{2\log(1/\delta)}{T_a(t-1)}}\) as an <em>exploration bonus</em> that encourages the learner to explore actions that have not been selected frequently (notice the inverse relationship between \(T_a(t-1)\) and the exploration bonus).
And at the same time, choosing \(\delta\) is a delicate problem; a small value of \(\delta\) leads to a more aggressive exploration, while a large value of \(\delta\) leads to premature abandonment of the optimal action.</p>

<h2 id="theoretical-guarantees-of-ucb">Theoretical guarantees of UCB</h2>

<p>The UCB algorithm has been shown to have a sublinear regret bound:</p>

<p style="background-color: lightblue; padding: 10px;">
    <strong>Theorem (Lattimore and Szepesvári, 2020).</strong> If $\delta=1/n^2$, then the regret of the UCB algorithm is bounded by
    \[
        R_n = \mathcal{O}(\sqrt{nk\log n})
    \]
</p>

<p>As an intermediate step, we first prove a weaker result:</p>

<p><strong>Lemma.</strong> If $\delta=1/n^2$, then the regret of the UCB algorithm is bounded by</p>

\[\begin{align}
R_n \leq 3\sum_{i=1}^k \Delta_i + \sum_{i: \Delta_i \geq 0} \frac{16\log(n)}{\Delta_i}
\end{align}\]

<p>where \(\Delta_i := \mu^* - \mu_i\) is the gap between the optimal action and action \(i\).</p>


<!-- <ul class="taxonomy__index">
  
  
    <li>
      <a href="#2025">
        <strong>2025</strong> <span class="taxonomy__count">4</span>
      </a>
    </li>
  
    <li>
      <a href="#2024">
        <strong>2024</strong> <span class="taxonomy__count">6</span>
      </a>
    </li>
  
    <li>
      <a href="#2023">
        <strong>2023</strong> <span class="taxonomy__count">2</span>
      </a>
    </li>
  
</ul> -->

<!-- 


  <section id="2025" class="taxonomy__section">
    <h2 class="archive__subtitle">2025</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/probability_theory/" rel="permalink">Some personal notes on probability theory
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">A self-contained summary of some key results in probability theory.
I’ll mostly summarize the results from Durrett’s Probability: Theory and Examples, Bandit...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/fisher_information/" rel="permalink">What is Fisher information?
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">It bugs me that I often have hard time to recall what Fisher information is.
So let’s write it down here.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/confidence_sets_exact/" rel="permalink">Time-uniform confidence sets for Gaussian linear models
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">In statistical inference, we often want to construct confidence sets for the parameter of interest; for example, you may have heard of the 95% confidence int...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ucb/" rel="permalink">The upper confidence bound algorithm
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
Bandits are a class of reinforcement learning (RL) problems where a learner has to choose between different actions, each of which has an unknown reward.
Th...</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>

  <section id="2024" class="taxonomy__section">
    <h2 class="archive__subtitle">2024</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/why_i_do_math/" rel="permalink">Why I think mathematics is beautiful
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">A friend of mine asked me why I think mathematics is beautiful.
I believe the exact answer does not matter, but it is important to have an answer.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/modern_hashing/" rel="permalink">Modern hashing made simple
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          9 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
This is a short personal note on “Modern Hashing Made Simple” by Bender et al. (2024).
I’m going to present this paper for the Advanced Graph Algorithms and...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/jane_street_aug24/" rel="permalink">Jane Street Puzzle - August 2024
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
I decided to slack off my exam studying with Jane Street’s puzzle.
I first read the problem in early August, forgot about it, and then submitted my answer o...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/expectation_counting/" rel="permalink">Counting with expectation
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Problem 10 (Individual test, ARML 2013).
For a positive integer \(n\), let \(C(n)\) equal the number of pairs of consecutive \(1\)’s in the binary representa...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/kl_upper_bound/" rel="permalink">An upper bound for the Kullback-Leibler divergence
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Zürich is so hot now in the night that I couldn’t fall asleep.
While lying on the bed, I arrived at an interesting upper bound for the KL divergence (relativ...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/opt_cheatsheet/" rel="permalink">Mathematical optimization cheatsheet
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">In this cheatsheet, I will discuss many concepts that are essential in the analysis of optimization algorithms.

</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>

  <section id="2023" class="taxonomy__section">
    <h2 class="archive__subtitle">2023</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/rate_distortion/" rel="permalink">Rate-distortion theory
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">In this post, I will summarize Shannon’s rate-distortion theory, including some self-contained definitions and proofs to the converse and direction part of t...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/channel_coding_proof/" rel="permalink">Noisy-channel coding theorem
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          9 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Here is my second attempt to understand the proof for the channel coding theorem.
My initial exposure to this concept was through Professor Amos Lapidoth’s l...</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>
 -->

  </div>
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/khanhvu207" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
      
        
          <li><a href="https://github.com/khanhvu207" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 Khánh Vũ. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
