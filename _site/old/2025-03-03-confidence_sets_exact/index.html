<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Time-uniform confidence sets for Gaussian linear models - EntropyMaxxing</title>
<meta name="description" content="">


  <meta name="author" content="Khánh Vũ">
  


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="EntropyMaxxing">
<meta property="og:title" content="Time-uniform confidence sets for Gaussian linear models">
<meta property="og:url" content="http://localhost:4000/old/2025-03-03-confidence_sets_exact/">












  

  


<link rel="canonical" href="http://localhost:4000/old/2025-03-03-confidence_sets_exact/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Khánh Vũ",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="EntropyMaxxing Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- for mathjax support -->

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js", "AMSmath.js", "AMSsymbols.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\]"], ["\\[","\\]"] ],
        processEscapes: false,
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] },
      TeX: {
        Macros: {
        }
      }
    });
  </script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js"></script>


<!-- Use katex instead -->


<!-- Theme stylesheets: light and dark -->
<link id="light-theme-css" rel="stylesheet" href="/assets/css/main.css" media="all">
<link id="dark-theme-css" rel="stylesheet" href="/assets/css/dark.css" media="not all">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



<script>
  (function() {
    var lightLink = document.getElementById('light-theme-css');
    var darkLink = document.getElementById('dark-theme-css');
    function applyTheme(theme) {
      if (theme === 'dark') {
        lightLink.media = 'not all';
        darkLink.media = 'all';
      } else {
        lightLink.media = 'all';
        darkLink.media = 'not all';
      }
    }
    // Initialize theme based on saved preference
    applyTheme(localStorage.getItem('theme'));
    document.addEventListener('DOMContentLoaded', function() {
      var btn = document.getElementById('theme-toggle');
      if (!btn) return;
      function updateIcon() {
        if (darkLink.media === 'all') {
          btn.innerHTML = '<i class="fas fa-sun"></i>';
        } else {
          btn.innerHTML = '<i class="fas fa-moon"></i>';
        }
      }
      btn.addEventListener('click', function() {
        var darkMode = (darkLink.media === 'all');
        var newTheme = darkMode ? 'light' : 'dark';
        // Save preference, then reload to apply cleanly
        localStorage.setItem('theme', newTheme);
        location.reload();
      });
      updateIcon();
    });
  })();
</script>

    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--posts">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          EntropyMaxxing
          
        </a>
        <!-- <div class="cute-gif"> -->
          <!-- <img src="../assets/images/penguin.gif" style="width: 25%; display: inline-block;" alt="cute gif"> -->
        <!-- </div> -->
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li></ul>
        
        <button id="theme-toggle" class="search__toggle" type="button" aria-label="Toggle dark mode">
          <i class="fas fa-moon"></i>
        </button>
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  


  <div class="archive">
    
      <h1 id="page-title" class="page__title">Time-uniform confidence sets for Gaussian linear models</h1>
    
    <p>In statistical inference, we often want to construct confidence sets for the parameter of interest; for example, you may have heard of the <a href="https://en.wikipedia.org/wiki/Confidence_interval">95% confidence interval</a>.
Confidence sets are a way to quantify the uncertainty in our estimates.
At its core, the construction of confidence sets is typically achieved through inverting some concentration inequalities.
<!-- We shall explore this in a setting where the estimator is [asymptotically normal](https://en.wikipedia.org/wiki/Asymptotic_distribution#Central_limit_theorem) under some regularity conditions. --></p>

<p><strong>The setting.</strong>
We observe \(n\) samples \(\{(Y_t, x_t)\}_{t=1}^n\) that follows the linear regression model</p>

\[Y_t = \langle x_t, \theta_\star \rangle + \eta_t,\]

<p>where the design vector \(x_t \in \mathbb{R}^d\) is fixed and known, the noise \(\eta_t\) is drawn i.i.d from a Gaussian \(\mathcal{N}(0, 1)\) and the parameter of interest is \(\theta_\star \in \mathbb{R}^d\).
For simplicity, we assume that the Gram matrix \(V:= X^\top X = \sum_{t=1}^n x_t x_t^\top\) is non-singular (here, \(X = [x_1^\top, \ldots, x_n^\top]^\top\)).
For brevity, we can write $Y = X\theta_\star + \eta$ with $Y\in \mathbb{R}^n$ and $\eta \in \mathbb{R}^n$.</p>

<p>Our goal is to construct a sequence of confidence sets \(C_1, C_2, \ldots\) such that \(\Pr(\exists n \ge 1: \theta_\star \notin C_n) \le \delta\) for some confidence level \(\delta \in (0, 1)\).
We will start with the maximum-likelihood estimator and then construct the confidence set for a certain $n$. 
Under the above assumptions, the maximum-likelihood estimator \(\hat{\theta}\) is given by</p>

\[\hat{\theta} = V^{-1} X^\top Y,\]

<p>which turns out to be a Gaussian because $Y$ is a Gaussian vector as given. 
In particular, we can write</p>

<!-- which is also known to be [asymptotically normal](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Consistency) (well, in fact $$\hat{\theta}$$ is normal already due to the Gaussian noise!). -->

<!-- More precisely, the distribution of $$\hat{\theta}$$ converges to a Gaussian distribution when $$n$$ is large, i.e.,

$$
    \hat{\theta} \sim \mathcal{N}(\theta_\star, n^{-1}\mathcal{I}(\theta_\star)^{-1}).
$$

Above, $$\mathcal{I}(\theta_\star)$$ is the Fisher information matrix at $$\theta_\star$$.
It is also known that $$\hat{\theta}$$ is [asymptotically efficient](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Efficiency), i.e., it achieves the [Cramér-Rao lower bound](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound)

$$
    \mathbb{V}(\hat{\theta}) = n^{-1} \mathcal{I}(\theta_\star)^{-1}
$$

This is a bless because it allows us to work out the formula for the inversed Fisher information matrix:

$$
\begin{align*}
    \mathbb{V}(\hat{\theta}) &= \mathbb{V}(V^{-1} X^\top Y) \\
    &= \mathbb{V}(V^{-1} X^\top (X \theta_\star + \eta)) \\
    &= V^{-1} X^\top \mathbb{V}(\eta) X V^{-1} \\
    &=  V^{-1} X^\top X V^{-1} \\
    &=  V^{-1}.
\end{align*}
$$

From this we then have that: -->

\[\begin{align*}
    \hat{\theta} &amp;\sim \mathcal{N}(\theta_\star,  V^{-1}) \\
     V^{1/2}(\hat{\theta} - \theta_\star) &amp;\sim \mathcal{N}(0, I_d)
\end{align*}\]

<p>Let \(Z :=  V^{1/2}(\hat{\theta} - \theta_\star)\), then we have \(\|Z\|_2^2 =  \|\hat{\theta}-\theta_\star\|_{V}^2\) follows a \(\mathcal{X}_d^2\)-distribution with \(d\) degrees of freedom.
From <a href="https://stats.stackexchange.com/a/4821/301376">the tail bounds of the \(\chi^2\)-distribution</a>, we have</p>

\[\begin{align*}
    \Pr\left(\|Z\|_2^2 \geq d + 2\sqrt{d\log(1/\delta)} + 2\log(1/\delta)\right) &amp;\leq \delta
\end{align*}\]

<p>So if we define the confidence set \(C_n\) as</p>

\[C_n = \left\{\theta \in \mathbb{R}^d: \|\hat{\theta}-\theta\|_{V}^2 \leq  d + 2\sqrt{d\log(1/\delta)} + 2\log(1/\delta)\right\},\]

<p>then it is a \((1-\delta)\)-confidence set for \(\theta_\star\).</p>

<p>Using union bound, we can construct a sequence of confidence sets \(C_1, C_2, \ldots\) such that \(\Pr(\exists n \ge 1: \theta_\star \notin C_n) \leq \delta\) by choosing a larger confidence set for each \(n\):</p>

\[C_n = \left\{\theta \in \mathbb{R}^d: \|\hat{\theta}-\theta\|_{V}^2 \leq  d + 2\sqrt{d\log(n(n+1)/\delta)} + 2\log(n(n+1)/\delta)\right\}.\]

<p>Geometrically, the confidence set \(C_n\) is an ellipsoid centered at \(\hat{\theta}\) with the principal axes aligned with the eigenvectors of the Gram matrix \(V\).
The length of the axes is determined by the eigenvalues of the Gram matrix \(V\) and the confidence level \(\delta\).
To see this, for any confidence set that is of the form \(C_n = \{\theta :\|\hat{\theta} - \theta\|_V^2 \le \beta\}\), we can rewrite it as</p>

\[C_n = \hat{\theta} + \beta^{1/2} V^{-1/2} \mathcal{B}_d,\]

<p>where \(\mathcal{B}_d\) is the unit \(\ell_2\)-ball in \(\mathbb{R}^d\).
Furthermore, the volume of this ellipsoid is exactly the determinant of \(\beta^{1/2} V^{-1/2}\).
The calculation of this determinant is a bit dense but it invokes the <em>Elliptical potential lemma</em> (see Lemma 19.4 in <a href="https://tor-lattimore.com/downloads/book/book.pdf">Bandit Algorithms</a>) which turns out to scale as \(\mathcal{O}\left(\frac{\log n}{n}\right)^{d/2}\).
This basically agrees with the classical concentration rate \(\mathcal{O}(1/\sqrt{n})\) from the <a href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality">Hoeffding’s inequality</a> in the 1-dimensional case, where the extra \(\log n\) factor arises due to the time-uniform guarantee.</p>


<!-- <ul class="taxonomy__index">
  
  
    <li>
      <a href="#2025">
        <strong>2025</strong> <span class="taxonomy__count">1</span>
      </a>
    </li>
  
</ul> -->

<!-- 


  <section id="2025" class="taxonomy__section">
    <h2 class="archive__subtitle">2025</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/monty_hall/" rel="permalink">Monty Hall problem with Baysian inference
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">One simple way to think about the Monty Hall problem is to use Baye’s rule.
For the sake of completeness, here is the problem statement:

</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>
 -->

  </div>
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/khanhvu207" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
      
        
          <li><a href="https://github.com/khanhvu207" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 Khánh Vũ. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
