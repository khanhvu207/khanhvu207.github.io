<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Some personal notes on probability theory - EntropyMaxxing</title>
<meta name="description" content="A self-contained summary of some key results in probability theory. I’ll mostly summarize the results from Durrett’s Probability: Theory and Examples, Bandit Algorithms (Lattimore and Szepesvári) and some other sources.">


  <meta name="author" content="Khánh Vũ">
  
  <meta property="article:author" content="Khánh Vũ">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="EntropyMaxxing">
<meta property="og:title" content="Some personal notes on probability theory">
<meta property="og:url" content="http://localhost:4000/probability_theory/">


  <meta property="og:description" content="A self-contained summary of some key results in probability theory. I’ll mostly summarize the results from Durrett’s Probability: Theory and Examples, Bandit Algorithms (Lattimore and Szepesvári) and some other sources.">







  <meta property="article:published_time" content="2025-03-16T00:00:00+01:00">





  

  


<link rel="canonical" href="http://localhost:4000/probability_theory/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Khánh Vũ",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="EntropyMaxxing Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- for mathjax support -->
<!-- 
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js", "AMSmath.js", "AMSsymbols.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  </script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
 -->

<!-- for mathjax support -->

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js", "AMSmath.js", "AMSsymbols.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\]"], ["\\[","\\]"] ],
        processEscapes: true
      },
      messageStyle: "none",
      "HTML-CSS": { availableFonts: ["TeX"] },
      TeX: {
        Macros: {
        }
      }
    });
  </script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js"></script>


<!-- Theme stylesheets: light and dark -->
<link id="light-theme-css" rel="stylesheet" href="/assets/css/main.css" media="all">
<link id="dark-theme-css" rel="stylesheet" href="/assets/css/dark.css" media="not all">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>


<script>
  (function() {
    var lightLink = document.getElementById('light-theme-css');
    var darkLink = document.getElementById('dark-theme-css');
    function applyTheme(theme) {
      if (theme === 'dark') {
        lightLink.media = 'not all';
        darkLink.media = 'all';
      } else {
        lightLink.media = 'all';
        darkLink.media = 'not all';
      }
    }
    // Initialize theme based on saved preference
    applyTheme(localStorage.getItem('theme'));
    document.addEventListener('DOMContentLoaded', function() {
      var btn = document.getElementById('theme-toggle');
      if (!btn) return;
      function updateIcon() {
        if (darkLink.media === 'all') {
          btn.innerHTML = '<i class="fas fa-sun"></i>';
        } else {
          btn.innerHTML = '<i class="fas fa-moon"></i>';
        }
      }
      btn.addEventListener('click', function() {
        var darkMode = (darkLink.media === 'all');
        var newTheme = darkMode ? 'light' : 'dark';
        // Save preference, then reload to apply cleanly
        localStorage.setItem('theme', newTheme);
        location.reload();
      });
      updateIcon();
    });
  })();
</script>

    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--posts">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          EntropyMaxxing
          
        </a>
        <!-- <div class="cute-gif"> -->
          <!-- <img src="../assets/images/penguin.gif" style="width: 25%; display: inline-block;" alt="cute gif"> -->
        <!-- </div> -->
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li></ul>
        
        <button id="theme-toggle" class="search__toggle" type="button" aria-label="Toggle dark mode">
          <i class="fas fa-moon"></i>
        </button>
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/avatar.png" alt="Khánh Vũ" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">Khánh Vũ</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>i’m just a chill guy :)</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <div class="archive">
    
      <h1 id="page-title" class="page__title">Some personal notes on probability theory</h1>
    
    <p>A self-contained summary of some key results in probability theory.
I’ll mostly summarize the results from <a href="https://www.cambridge.org/ch/universitypress/subjects/statistics-probability/probability-theory-and-stochastic-processes/probability-theory-and-examples-5th-edition?format=HB">Durrett’s Probability: Theory and Examples</a>, <a href="https://tor-lattimore.com/downloads/book/book.pdf">Bandit Algorithms (Lattimore and Szepesvári)</a> and some other sources.</p>

<h2 id="0-measure-theoretic-probability">0. Measure-theoretic probability</h2>

<p><strong>($\sigma$-algebra and probability measure)</strong>
Let $\Omega$ be a set of outcomes.
A set of events $\mathcal{F} \subseteq 2^\Omega$ is a $\sigma$-algebra if $\Omega\in\mathcal{F}$, $A^c \in \mathcal{F}$ for all $A \in \mathcal{F}$ and $\bigcup_i A_i \in \mathcal{F}$ for all $A_i \in \mathcal{F}$.
A function $\mathbb{P}: \mathcal{F} \to \mathbb{R}$ is a probability measure if $\mathbb{P}(\Omega) = 1$ and $\mathbb{P}(A) \ge 0$ for all $A \in \mathcal{F}$.
Moreover, $\mathbb{P}(A^c) = 1 - \mathbb{P}(A)$ for all $A \in \mathcal{F}$ and $\mathbb{P}(\bigcup_i A_i) = \sum_i \mathbb{P}(A_i)$ for all $A_i \in \mathcal{F}$ such that $A_i \cap A_j = \emptyset$ for all $i \neq j$.
A set $\mathcal{G}$ is a sub-$\sigma$-algebra of $\mathcal{F}$ if $\mathcal{G} \subseteq \mathcal{F}$ and $\mathcal{G}$ is a $\sigma$-algebra.
The restriction of $\mathbb{P}$ to $\mathcal{G}$ is denoted by $\mathbb{P}|_{\mathcal{G}}$.</p>

<p>For an event $A\in\mathcal{F}$, we denote the probability of $A$ by $\mathbb{P}(A)$.</p>

<p><strong>(Measurable space)</strong>
A measurable space is a pair $(\Omega, \mathcal{F})$ where $\Omega$ is a set and $\mathcal{F}$ is a $\sigma$-algebra on $\Omega$.</p>

<p><strong>($\mathcal{F}/\mathcal{G}$-measurable map)</strong>
Let $(\Omega, \mathcal{F})$ be a measurable space and let $\mathcal{X}$ be any set and $\mathcal{G}\subseteq 2^{\mathcal{X}}$.
A map $X:\Omega \to \mathcal{X}$ is $\mathcal{F}/\mathcal{G}$-measurable if $X^{-1}(A) \in \mathcal{F}$ for all $A \in \mathcal{G}$.
Here, $\mathcal{G}$ <em>need not</em> to be a $\sigma$-algebra.
If $X$ is $\mathcal{F}/\mathcal{G}$-measurable, then it is also $\mathcal{F}/\sigma(\mathcal{G})$-measurable, where $\sigma(\mathcal{G})$ is the smallest $\sigma$-algebra containing $\mathcal{G}$.</p>

<p>Given a map $X:\Omega\to\mathcal{X}$ between measurable spaces $(\Omega, \mathcal{F})$ and $(\mathcal{X}, \mathcal{G})$, we define \(\sigma(X) = \{X^{-1}(A): A\in\mathcal{G}\}\) to be the $\sigma$-algebra generated by $X$.
Here, the term “generated” means that $\sigma(X)$ is the <em>smallest</em> $\sigma$-algebra containing $X^{-1}(A)$ for all $A \in \mathcal{G}$.
The map $X$ is $\mathcal{F}/\mathcal{G}$-measurable if and only if $\sigma(X) \subseteq \mathcal{F}$.
In fact, $\sigma(X)$ is a sub-$\sigma$-algebra of $\mathcal{F}$ and is also the smallest sub-$\sigma$-algebra for which $X$ is measurable.
Furthurmore, if $\mathcal{G} = \sigma(\mathcal{A})$ itself is generated by a set $\mathcal{A}\subseteq 2^{\mathcal{X}}$, it is enough to check that \(X^{-1}(\mathcal{A}) = \{X^{-1}(A) : A\in\mathcal{A}\}\) is a subset of $\mathcal{F}$.</p>

<p><strong>(Borel $\sigma$-algebra)</strong>
If $\mathcal{G}$ is a set of open intervals in $\mathbb{R}$, then the Borel $\sigma$-algebra $\mathcal{B}(\mathbb{R})$ is the smallest $\sigma$-algebra containing $\mathcal{G}$.</p>

<hr />
<p><strong>(Random variable)</strong>
A random variable on a measurable space $(\Omega, \mathcal{F})$ is a $\mathcal{F}/\mathcal{B}(\mathbb{R})$-measurable map $X:\Omega \to \mathbb{R}$.</p>

<p style="background-color: lightgreen; padding: 10px;">
$\color{darkgreen}{\text{(Lemma 0.1: Doob–Dynkin lemma (also known as factorization lemma))}}$
Assume that we are given measurable spaces $(\Omega, \mathcal{F})$, $(\mathcal{X}, \mathcal{G})$ and $(\mathcal{Y}, \mathcal{H})$, and $X:\Omega\to\mathcal{X}$ and $Y:\Omega\to\mathcal{Y}$ are the random elements (generalization of random variables to higher dimensions), if $(\mathcal{Y}, \mathcal{H})$ is a Borel space, then $Y$ is $\sigma(X)$-measureable if and only if there exists a $\mathcal{G}/\mathcal{H}$-measurable map $f:\mathcal{X}\to\mathcal{Y}$ such that $Y = f\circ X$.
Here, $Y$ is $\sigma(X)$-measurable means that $\sigma(Y) \subseteq \sigma(X)$, i.e. knowing $X$ gives us information about $Y$.
</p>

<hr />
<p><strong>(Filtration)</strong>
Given a measurable space $(\Omega, \mathcal{F})$, a filtration is a sequence of \((\mathcal{F}_t)_{t=0}^n\) of sub-$\sigma$-algebras of $\mathcal{F}$ such that \(\mathcal{F}_0 \subseteq \mathcal{F}_1 \subseteq \ldots \subseteq \mathcal{F}_n\).
Also we define \(\mathcal{F}_\infty = \sigma\left(\bigcup_{t=0}^\infty \mathcal{F}_t\right)\) to be the smallest $\sigma$-algebra containing the union of all \(\mathcal{F}_t\).</p>

<p>A sequence of random variables \((X_t)_{t=1}^n\) if <em>adapted</em> to the filtration \(\mathbb{F} = (\mathcal{F}_t)_{t=0}^n\) if \(X_t\) is \(\mathcal{F}_{t}\)-measurable for all $t\in[n]$.
For brevity, we can say \((X_t)_t\) is $\mathbb{F}$-adapted.
Finally, \((X_t)_t\) is $\mathbb{F}$-predictable if $X_t$ is \(\mathcal{F}_{t-1}\)-measurable for all $t\in[n]$.</p>

<hr />
<p><strong>(Conditional probability)</strong>
Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space.
The conditional probability $\mathbb{P}(A|B)$ of $A$ given $B$ is defined as \(\mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}\).
Intuitively, this tells us how large the portion of $A$ is in $B$.</p>

<p><strong>(Independence)</strong>
Two events $A, B\in\mathcal{F}$ are independent if $\mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B)$.
Alternatively, we can say that $A$ and $B$ are independent if $\mathbb{P}(A|B) = \mathbb{P}(A)$.
Two random variables $X$ and $Y$ are independent if $\sigma(X)$ and $\sigma(Y)$ are independent $\sigma$-algebras, i.e. $\mathbb{P}(X\in A, Y\in B) = \mathbb{P}(X\in A)\mathbb{P}(Y\in B)$ for all $A, B\in\mathcal{B}(\mathbb{R})$.</p>

<hr />
<p><strong>(Expectation)</strong>
Given a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, the expectation of a random variable $X:\Omega\to\mathbb{R}$ is defined as its Lebesgue integral with respect to $\mathbb{P}$:</p>

\[\mathbb{E}[X] = \int_\Omega X(\omega) d\mathbb{P}(\omega)\]

<p>To rigourously define what exactly this is, we shall need two facts about integration.
First, the integral of an indicator function is the probability of the event:
If \(X(\omega) = \mathbb{I}\{\omega\in A\}\) for some $A\in\mathbb{F}$, then $\int_\Omega X(\omega) d\mathbb{P}(\omega) = \mathbb{P}(A)$.
Second, the integral is a linear operator.</p>

<p>Now, if \(X(\omega) = \sum_{i=1}^n a_i \mathbb{I}\{\omega\in A_i\}\) for some $A_i\in\mathcal{F}$, then we can write the integral as:</p>

\[\int_\Omega X(\omega) d\mathbb{P}(\omega) = \sum_{i=1}^n a_i \int_\Omega \mathbb{I}\{\omega\in A_i\} d\mathbb{P}(\omega) = \sum_{i=1}^n a_i \mathbb{P}(A_i)\]

<p>Such an $X$ is called a simple function.
Then, the expectation is an approximation from below:</p>

\[\int_\Omega X(\omega) d\mathbb{P}(\omega) = \sup\left\{\int_\Omega h(\omega) d\mathbb{P}(\omega) : \text{$h$ is simple and $0\le h \le X$ pointwise} \right\}\]

<hr />
<p><strong>(Stochastic process)</strong>
A stochastic process on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ is a collection of random variables $(X_t)_{t\in T}$ indexed by a set $T$.</p>

<p><strong>($\mathbb{P}$-almost surely)</strong>
When two random variables $X$ and $Y$ are equal almost surely, we write $X = Y$ $\mathbb{P}$-almost surely, denoted by $X = Y$ $\mathbb{P}$-a.s., if $\mathbb{P}(X = Y) = 1$.
To put it another way, they disagree on a set of measure zero.</p>

<p><strong>(Martingale)</strong>
Let $X_1, X_2, \ldots$ be a sequence of random variables on $(\Omega, \mathcal{F}, \mathbb{P})$ and \(\mathbb{F} = (\mathcal{F}_t)_{t=1}^n\) a filtration of $\mathcal{F}$ (we allow $n = \infty$).
A $\mathbb{F}$-adapted sequence of random variables \((X_t)_{t\in\mathbb{N}_+}\) is a $\mathbb{F}$-adapted martingale if:
(a) \(\mathbb{E}[X_t | \mathcal{F}_{t-1}] = X_{t-1}\) almost surely for all \(t\in\{2, 3, \ldots\}\) and
(b) \(X_t\) is integrable.
If we replace the equality with less-than or greater-than, we call \((X_t)_t\) a supermartingale or submartingale respectively.</p>

<p>A fair betting game is one real-life example, where \(S_t\) is the total money you have after $t$ rounds of a fair game which can be proven to be a martingale.</p>

<p><strong>(Stopping time)</strong>
Let \(\mathbb{F} = (\mathcal{F}_t)_{t\in\mathbb{N}}\) be a filtration.
A random variable \(\tau:\Omega\to\mathbb{N}\cup\{\infty\}\) is a stopping time with respect to \(\mathbb{F}\) if for all \(t\in\mathbb{N}\), the event \(\{\tau \le t\} \in \mathcal{F}_t\) (or we can say \(\mathbb{I}\{\tau \le t\}\) is \(\mathcal{F}_t\)-measurable).
The $\sigma$-algebra at the stopping time $\tau$ is:</p>

\[\mathcal{F}_\tau = \{A \in \mathcal{F}_\infty : A \cap \{\tau \le t\} \in \mathcal{F}_t \text{ for all $t$} \}\]

<p style="background-color: lightblue; padding: 10px;">
$\color{darkblue}{(\text{Theorem 0.1: Doob's optional stopping})}$
Let $\mathbb{F} = (\mathcal{F}_t)_{t\in\mathbb{N}}$ be a filtration and $(X_t)_{t\in\mathbb{N}}$ be an $\mathbb{F}$-adapted martingale and $\tau$ an $\mathbb{F}$-stopping time such that <i>at least one</i> of the following conditions hold:

<br />
1. $\exists n\in\mathbb{N}$ such that $\mathbb{P}(\tau &gt; n) = 0$, e.g. $\tau$ is almost surely bounded.

<br />
2. $\mathbb{E}[\tau] &lt; \infty$ and $\exists c\in\mathbb{R}$ such that for all $t\in\mathbb{N}$, $\mathbb{E}\left[|X_{t+1} - X_t| ~\middle| \mathcal{F}_t\right] \le c$ almost surely.

<br />
3. $\exists c$ such that $|X_{t\land \tau}| \le c$ almost surely for all $t\in\mathbb{N}$.

<br />
Then, $X_\tau$ is almost surely well defined and $\mathbb{E}[X_\tau] = \mathbb{E}[X_0]$.
</p>

<p>One practical consequence of this theorem is that if you play a fair betting game and try to outsmart the casino by stopping at a certain time, say when \(S_t \ge \$100\), you will expect to spend eternity in the casino, e.g. if $S_t$ is the total money you have after $t$ rounds of a fair game, then either $\mathbb{E}[S_\tau] = 0$ or $\mathbb{E}[\tau] = \infty$.</p>

<p style="background-color: lightblue; padding: 10px;">
$\color{darkblue}{(\text{Theorem 0.2: Maximal inequality (also known as Ville's inequality)})}$
Let $(X_t)_{t=0}^\infty$ be a supermartingale with $X_t\ge 0$ almost surely for all $t$.
Then, for any $\epsilon&gt;0$,

$$
    \mathbb{P}\left(\sup_{t\in\mathbb{N}} X_t \ge \epsilon\right) \le \frac{\mathbb{E}[X_0]}{\epsilon}.
$$
<!-- As a remark, this is a generalization of the Markov's inequality. -->
</p>

<!-- _Proof._
Let define an event $$A_n = \{\sup_{t\le n} X_t \ge \epsilon\}$$.
We have that $A_1 \subseteq A_2 \subseteq \ldots$ and that:

$$
    \lim_{n\to \infty} A_n = \{\sup_{t\in\mathbb{N}} X_t \ge \epsilon\}
$$

Furthermore, let us define $$\tau = (n+1) \land \min\{t\le n: X_t \ge \epsilon\}$$.
Clearly, $\tau$ is a stopping time and $\mathbb{E}[X_0] \ge \mathbb{E}[X_\tau]$.
By theorem 0.1, we have that:

$$
\begin{align*}
    \mathbb{E}[X_0] \ge \mathbb{E}[X_\tau] \ge \mathbb{E}[X_\tau\mathbb{I}\{\tau \le n\}] \ge \mathbb{E}[\epsilon\mathbb{I}\{\tau \le n\}] = \epsilon \mathbb{P}(\tau \le n) = \epsilon \mathbb{P}(A_n)
\end{align*}
$$

Here, the second inequality stemmed from the definition of stopping time, i.e. $$\mathbb{E}[X_\tau\mathbb{I}\{\tau > n\}] = 0$$:

$$
    \mathbb{E}[X_\tau] = \mathbb{E}[X_\tau\mathbb{I}\{\tau \le n\}] + \underbrace{\mathbb{E}[X_\tau\mathbb{I}\{\tau > n\}]}_{=0} \ge \mathbb{E}[X_\tau\mathbb{I}\{\tau \le n\}] 
$$ -->

<h2 id="1-law-of-large-numbers">1. Law of large numbers</h2>

<p><strong>(Convergence in probability)</strong>
We say that $X_n$ converges to $X$ in probability if for every $\epsilon &gt; 0$, $\lim_{n \to \infty} \Pr(|X_n - X| &gt; \epsilon) = 0$, denoted by $X_n \overset{p}{\longrightarrow} X$.</p>

<p><strong>(Convergence in $L^r$)</strong>
We say that $X_n$ converges to $X$ in $L^r$ if $\lim_{n \to \infty} \mathbb{E}(|X_n - X|^r) = 0$, denoted by $X_n \overset{L^r}{\longrightarrow} X$.</p>

<p><strong>(Uncorrelated variables)</strong>
Two random variables $X$ and $Y$ are uncorrelated if $\mathbb{E}(XY) = \mathbb{E}(X)\mathbb{E}(Y)$.</p>

<p style="background-color: lightgreen; padding: 10px;">
$\color{darkgreen}{\text{(Lemma 1.1)}}$
Let $X_1, X_2, \ldots$ be a sequence of uncorrelated random variables with $\mathbb{E}(X_i) &lt; \infty$, then we have that $\mathbb{V}(X_1 + \ldots + X_n) = \mathbb{V}(X_1) + \ldots + \mathbb{V}(X_n)$.
</p>

<hr />
<p style="background-color: lightblue; padding: 10px;">
$\color{darkblue}{(\text{Theorem 1.1: $L^2$ weak law})}$
Let $X_1, X_2, \ldots$ be a sequence of uncorrelated random variables with $\mathbb{E}(X_i) = \mu$ and $\mathbb{V}(X_i) \le C &lt; \infty$.
If $S_n := X_1 + \ldots + X_n$, then $S_n/n \overset{L^2}{\longrightarrow} \mu$.
</p>

<p><em>Proof.</em>
We have that $\mathbb{E}[|S_n/n - \mu|^2] = \mathbb{V}(S_n/n) \le \frac{C/n}{n^2} \to 0$ as $n \to \infty$.
Here, we used Lemma 1.1 to compute the variance of $S_n/n$.</p>

<hr />
<p><strong>(Chebyshev’s inequality)</strong>
For any random variable $X$ and $r &gt; 0$, $\Pr(|X| \ge \epsilon) \le \epsilon^{-r}\mathbb{E}(|X|^r)$.</p>

<p>One small remark is that Chebyshev’s inequality is generally not a sharp inequality (for example try bounding standard normal variables), however, it cannot be improved in <a href="https://en.wikipedia.org/wiki/Chebyshev%27s_inequality#Sharpness_of_bounds">certain cases</a>.</p>

<p style="background-color: lightgreen; padding: 10px;">
$\color{darkgreen}{\text{(Lemma 1.2: Convergence in $L^r$ implies convergence in probability)}}$
For $r &gt; 0$, if $Z_n \overset{L^r}{\longrightarrow} 0$, then $Z_n \overset{p}{\longrightarrow} 0$.
</p>

<p><em>Proof.</em> Since $\mathbb{E}(|Z_n|^r) \to 0$, the proof follows directly from Chebyshev’s inequality applying to the random variable $Z_n$.</p>

<p style="background-color: lightblue; padding: 10px;">
$\color{darkblue}{(\text{Theorem 1.2: Weak law of large numbers})}$
Let $X_1, X_2, \ldots$ be a sequence of uncorrelated random variables with $\mathbb{E}(X_i) = \mu$ and $\mathbb{V}(X_i) \le C &lt; \infty$.
If $S_n := X_1 + \ldots + X_n$, then $S_n/n \overset{p}{\longrightarrow} \mu$.
</p>

<p><em>Proof.</em> Follows from Lemma 1.2 with $r = 2$ and the $L^2$ weak law.</p>

<p>If we relax the assumption of bounded variance, we can still obtain a weak law of large numbers with i.i.d assumption and a weaker variance assumption.</p>

<p style="background-color: lightblue; padding: 10px;">
$\color{darkblue}{(\text{Theorem 1.3: Weak law of large numbers with relaxed variance assumption})}$
Let $X_1, X_2, \ldots$ be a sequence of i.i.d random variables with $x\cdot\Pr(|X_i| &gt; x) \to 0$ as $x \to \infty$.
Let $\mu_n := \mathbb{E}[X_1\cdot\mathbb{I}\{|X_1| \le n\}]$.
Then, $S_n/n - \mu_n \overset{p}{\longrightarrow} 0$.
</p>

<p style="background-color: lightblue; padding: 10px;">
$\color{darkblue}{(\text{Theorem 1.4: Weak law of large numbers for i.i.d random variables})}$
Let $X_1, X_2, \ldots$ be a sequence of i.i.d random variables with $\mathbb{E}[|X_1|] &lt; \infty$.
Let $\mu := \mathbb{E}[X_1]$.
Then, $S_n/n \overset{p}{\longrightarrow} \mu$.
</p>

<p><em>Proof sketch.</em> Use theorem 1.3 and the dominated convergence theorem.</p>

<h2 id="2-borel-cantelli-lemmas-coming-soon">2. Borel-Cantelli lemmas (coming soon)</h2>


<!-- <ul class="taxonomy__index">
  
  
    <li>
      <a href="#2025">
        <strong>2025</strong> <span class="taxonomy__count">4</span>
      </a>
    </li>
  
    <li>
      <a href="#2024">
        <strong>2024</strong> <span class="taxonomy__count">6</span>
      </a>
    </li>
  
    <li>
      <a href="#2023">
        <strong>2023</strong> <span class="taxonomy__count">2</span>
      </a>
    </li>
  
</ul> -->

<!-- 


  <section id="2025" class="taxonomy__section">
    <h2 class="archive__subtitle">2025</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/probability_theory/" rel="permalink">Some personal notes on probability theory
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">A self-contained summary of some key results in probability theory.
I’ll mostly summarize the results from Durrett’s Probability: Theory and Examples, Bandit...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/fisher_information/" rel="permalink">What is Fisher information?
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">It bugs me that I often have hard time to recall what Fisher information is.
So let’s write it down here.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/confidence_sets_exact/" rel="permalink">Time-uniform confidence sets for Gaussian linear models
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">In statistical inference, we often want to construct confidence sets for the parameter of interest; for example, you may have heard of the 95% confidence int...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ucb/" rel="permalink">The upper confidence bound algorithm
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
Bandits are a class of reinforcement learning (RL) problems where a learner has to choose between different actions, each of which has an unknown reward.
Th...</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>

  <section id="2024" class="taxonomy__section">
    <h2 class="archive__subtitle">2024</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/why_i_do_math/" rel="permalink">Why I think mathematics is beautiful
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">A friend of mine asked me why I think mathematics is beautiful.
I believe the exact answer does not matter, but it is important to have an answer.

</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/modern_hashing/" rel="permalink">Modern hashing made simple
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          9 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
This is a short personal note on “Modern Hashing Made Simple” by Bender et al. (2024).
I’m going to present this paper for the Advanced Graph Algorithms and...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/jane_street_aug24/" rel="permalink">Jane Street Puzzle - August 2024
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
I decided to slack off my exam studying with Jane Street’s puzzle.
I first read the problem in early August, forgot about it, and then submitted my answer o...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/expectation_counting/" rel="permalink">Counting with expectation
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Problem 10 (Individual test, ARML 2013).
For a positive integer \(n\), let \(C(n)\) equal the number of pairs of consecutive \(1\)’s in the binary representa...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/kl_upper_bound/" rel="permalink">An upper bound for the Kullback-Leibler divergence
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Zürich is so hot now in the night that I couldn’t fall asleep.
While lying on the bed, I arrived at an interesting upper bound for the KL divergence (relativ...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/opt_cheatsheet/" rel="permalink">Mathematical optimization cheatsheet
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">In this cheatsheet, I will discuss many concepts that are essential in the analysis of optimization algorithms.

</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>

  <section id="2023" class="taxonomy__section">
    <h2 class="archive__subtitle">2023</h2>
    <div class="entries-list">
      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/rate_distortion/" rel="permalink">Rate-distortion theory
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">In this post, I will summarize Shannon’s rate-distortion theory, including some self-contained definitions and proofs to the converse and direction part of t...</p>
  </article>
</div>

      
        



<div class="list__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/channel_coding_proof/" rel="permalink">Noisy-channel coding theorem
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          9 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Here is my second attempt to understand the proof for the channel coding theorem.
My initial exposure to this concept was through Professor Amos Lapidoth’s l...</p>
  </article>
</div>

      
    </div>
    <a href="#page-title" class="back-to-top">Back to top &uarr;</a>
  </section>
 -->

  </div>
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/khanhvu207" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
      
        
          <li><a href="https://github.com/khanhvu207" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 Khánh Vũ. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
