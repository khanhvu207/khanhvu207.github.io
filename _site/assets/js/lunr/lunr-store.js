var store = [{
        "title": "Noisy-channel coding theorem",
        "excerpt":"Here is my second attempt to understand the proof for the channel coding theorem. My initial exposure to this concept was through Professor Amos Lapidoth’s lecture in Information Theory I. His presentation, though concise, was packed with ingenious methods that were challenging to fully comprehend at time. To better understand...","categories": [],
        "tags": [],
        "url": "/channel_coding_proof/",
        "teaser": null
      },{
        "title": "Rate-distortion theory",
        "excerpt":"In this post, I will summarize Shannon’s rate-distortion theory, including some self-contained definitions and proofs to the converse and direction part of the main theorem. The rate-distortion theorem plays a crucial role in modern signal processing, especially in understanding the limit of data compression. I will try to keep the...","categories": [],
        "tags": [],
        "url": "/rate_distortion/",
        "teaser": null
      },{
        "title": "An upper bound for the Kullback-Leibler divergence",
        "excerpt":"Zürich is so hot now in the night that I couldn’t fall asleep. While lying on the bed, I arrived at an interesting upper bound for the KL divergence (relative entropy) between two Bernoulli distributions. In this case, the KL divergence is expressed as: \\[D_\\text{KL}(p \\parallel q) := p\\log\\left(\\frac{p}{q}\\right) +...","categories": [],
        "tags": [],
        "url": "/kl_upper_bound/",
        "teaser": null
      },{
        "title": "Jane Street Puzzle - August 2024",
        "excerpt":"I decided to slack off my exam studying with Jane Street’s puzzle. I first read the problem in early August, forgot about it, and then submitted my answer on August 16—and got it right on the first try! (username: Khanh Vu). This month’s puzzle involves straightforward state analysis with a...","categories": [],
        "tags": [],
        "url": "/jane_street_aug24/",
        "teaser": null
      },{
        "title": "Modern hashing made simple",
        "excerpt":"This is a short personal note on “Modern Hashing Made Simple” by Bender et al. (2024). I’m going to present this paper for the Advanced Graph Algorithms and Optimization Seminar (Fall 2024) at ETH Zürich. My personal goal is to understand the paper well enough to present it in a...","categories": [],
        "tags": [],
        "url": "/modern_hashing/",
        "teaser": null
      },{
        "title": "Time-uniform confidence sets for Gaussian linear models",
        "excerpt":"In statistical inference, we often want to construct confidence sets for the parameter of interest; for example, you may have heard of the 95% confidence interval. Confidence sets are a way to quantify the uncertainty in our estimates. At its core, the construction of confidence sets is typically achieved through...","categories": [],
        "tags": [],
        "url": "/time_uniform_gaussian_ci/",
        "teaser": null
      },{
        "title": "What is Fisher information?",
        "excerpt":"It bugs me that I often have hard time to recall what Fisher information is. So let’s write it down here. At the high-level view, Fisher information shows us how the observations constrain the possible values of the parameter of interest; or to put it another way, how informative the...","categories": [],
        "tags": [],
        "url": "/fisher_information/",
        "teaser": null
      },{
        "title": "Monty Hall problem with Bayesian inference",
        "excerpt":"One simple way to think about the Monty Hall problem is to use Baye’s rule. For the sake of completeness, here is the problem statement: Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You...","categories": [],
        "tags": [],
        "url": "/monty_hall/",
        "teaser": null
      },{
        "title": "Estimating density ratios without knowing the densities",
        "excerpt":"Suppose we have two probability distributions $p$ and $q$ over the same space $\\mathcal{X}$, and we want to estimate the density ratio $\\frac{q(x)}{p(x)}$ for some $x \\in \\mathcal{X}$. The caveat is that we do not know the densities $p$ and $q$, but we have a way to sample from them....","categories": [],
        "tags": [],
        "url": "/density_ratio_estimation/",
        "teaser": null
      }]
