var store = [{
        "title": "Noisy-channel coding theorem",
        "excerpt":"Here is my second attempt to understand the proof for the channel coding theorem. My initial exposure to this concept was through Professor Amos Lapidoth’s lecture in Information Theory I. His presentation, though concise, was packed with ingenious methods that were challenging to fully comprehend at time. To better understand...","categories": [],
        "tags": [],
        "url": "/channel_coding_proof/",
        "teaser": null
      },{
        "title": "Rate-distortion theory",
        "excerpt":"In this post, I will summarize Shannon’s rate-distortion theory, including some self-contained definitions and proofs to the converse and direction part of the main theorem. The rate-distortion theorem plays a crucial role in modern signal processing, especially in understanding the limit of data compression. I will try to keep the...","categories": [],
        "tags": [],
        "url": "/rate_distortion/",
        "teaser": null
      },{
        "title": "Mathematical optimization cheatsheet",
        "excerpt":"In this cheatsheet, I will discuss many concepts that are essential in the analysis of optimization algorithms. In the first part, I will recite the definitions of convexity, smoothness, and strong convexity, which are fundamental properties in the realm of convex optimization on differentiable functions. In the second part, we...","categories": [],
        "tags": [],
        "url": "/opt_cheatsheet/",
        "teaser": null
      },{
        "title": "An upper bound for the Kullback-Leibler divergence",
        "excerpt":"Zürich is so hot now in the night that I couldn’t fall asleep. While lying on the bed, I arrived at an interesting upper bound for the KL divergence (relative entropy) between two Bernoulli distributions. In this case, the KL divergence is expressed as: \\[D_\\text{KL}(p \\parallel q) := p\\log\\left(\\frac{p}{q}\\right) +...","categories": [],
        "tags": [],
        "url": "/kl_upper_bound/",
        "teaser": null
      },{
        "title": "Counting with expectation",
        "excerpt":"Problem 10 (Individual test, ARML 2013). For a positive integer \\(n\\), let \\(C(n)\\) equal the number of pairs of consecutive \\(1\\)’s in the binary representation of \\(n\\). For example, \\(C(183)=C(10110111_2)=3\\). Compute \\(C(1) + C(2) + \\ldots + C(256)\\). Solution. You can go ahead with doing casework and will eventually discover...","categories": [],
        "tags": [],
        "url": "/expectation_counting/",
        "teaser": null
      },{
        "title": "Jane Street Puzzle - August 2024",
        "excerpt":"I decided to slack off my exam studying with Jane Street’s puzzle. I first read the problem in early August, forgot about it, and then submitted my answer on August 16—and got it right on the first try! (username: Khanh Vu). This month’s puzzle involves straightforward state analysis with a...","categories": [],
        "tags": [],
        "url": "/jane_street_aug24/",
        "teaser": null
      },{
        "title": "Modern hashing made simple",
        "excerpt":"This is a short personal note on “Modern Hashing Made Simple” by Bender et al. (2024). I’m going to present this paper for the Advanced Graph Algorithms and Optimization Seminar (Fall 2024) at ETH Zürich. My personal goal is to understand the paper well enough to present it in a...","categories": [],
        "tags": [],
        "url": "/modern_hashing/",
        "teaser": null
      },{
        "title": "Why I think mathematics is beautiful",
        "excerpt":"A friend of mine asked me why I think mathematics is beautiful. I believe the exact answer does not matter, but it is important to have an answer. Years ago, I visited the Rijksmuseum in Amsterdam—it is one of the biggest museums in the Northern European region. In my memories,...","categories": [],
        "tags": [],
        "url": "/why_i_do_math/",
        "teaser": null
      },{
        "title": "The upper confidence bound algorithm",
        "excerpt":"Bandits are a class of reinforcement learning (RL) problems where a learner has to choose between different actions, each of which has an unknown reward. The key difference between bandits and RL problems is that in bandits, there is an absence of states or transition between states. Through interaction with...","categories": [],
        "tags": [],
        "url": "/ucb/",
        "teaser": null
      },{
        "title": "Confidence sets for Gaussian linear models",
        "excerpt":"In statistical inference, we often want to construct confidence sets for the parameter of interest; for example, you may have heard of the 95% confidence interval. Confidence sets are a way to quantify the uncertainty in our estimates. At its core, the construction of confidence sets is typically achieved through...","categories": [],
        "tags": [],
        "url": "/confidence_sets_exact/",
        "teaser": null
      },{
        "title": "What is Fisher information?",
        "excerpt":"It bugs me that I often have hard time to recall what Fisher information is. So let’s write it down here. At the high-level view, Fisher information shows us how the observations constrain the possible values of the parameter of interest; or to put it another way, how informative the...","categories": [],
        "tags": [],
        "url": "/fisher_information/",
        "teaser": null
      },{
        "title": "Some personal notes on probability theory",
        "excerpt":"A self-contained summary of some key results in probability theory. I’ll mostly summarize the results from Durrett’s Probability: Theory and Examples, Bandit Algorithms (Lattimore and Szepesvári) and some other sources. 0. Measure-theoretic probability ($\\sigma$-algebra and probability measure) Let $\\Omega$ be a set of outcomes. A set of events $\\mathcal{F} \\subseteq...","categories": [],
        "tags": [],
        "url": "/probability_theory/",
        "teaser": null
      }]
