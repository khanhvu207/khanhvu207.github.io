---
layout: posts
title: Some personal notes on probability theory 
usemathjax: true
published: true
---

A self-contained summary of some key results in probability theory.
I'll mostly summarize the results from [Durrett's Probability: Theory and Examples](https://www.cambridge.org/ch/universitypress/subjects/statistics-probability/probability-theory-and-stochastic-processes/probability-theory-and-examples-5th-edition?format=HB), [Bandit Algorithms (Lattimore and SzepesvÃ¡ri)](https://tor-lattimore.com/downloads/book/book.pdf) and some other sources.

## 0. Measure-theoretic probability

**($\sigma$-algebra and probability measure)**
Let $\Omega$ be a set of outcomes.
A set $\mathcal{F} \subseteq 2^\Omega$ is a $\sigma$-algebra if $\Omega\in\mathcal{F}$, $A^c \in \mathcal{F}$ for all $A \in \mathcal{F}$ and $\bigcup_i A_i \in \mathcal{F}$ for all $A_i \in \mathcal{F}$.
A function $\mathbb{P}: \mathcal{F} \to \mathbb{R}$ is a probability measure if $\mathbb{P}(\Omega) = 1$ and $\mathbb{P}(A) \ge 0$ for all $A \in \mathcal{F}$.
Moreover, $\mathbb{P}(A^c) = 1 - \mathbb{P}(A)$ for all $A \in \mathcal{F}$ and $\mathbb{P}(\bigcup_i A_i) = \sum_i \mathbb{P}(A_i)$ for all $A_i \in \mathcal{F}$ such that $A_i \cap A_j = \emptyset$ for all $i \neq j$.
A set $\mathcal{G}$ is a sub-$\sigma$-algebra of $\mathcal{F}$ if $\mathcal{G} \subseteq \mathcal{F}$ and $\mathcal{G}$ is a $\sigma$-algebra.
The restriction of $\mathbb{P}$ to $\mathcal{G}$ is denoted by $\mathbb{P}|_{\mathcal{G}}$.

**(Measurable space)**
A measurable space is a pair $(\Omega, \mathcal{F})$ where $\Omega$ is a set and $\mathcal{F}$ is a $\sigma$-algebra on $\Omega$.

**($\mathcal{F}/\mathcal{G}$-measurable map)**
Let $(\Omega, \mathcal{F})$ be a measurable space and let $\mathcal{X}$ be any set and $\mathcal{G}\subseteq 2^{\mathcal{X}}$.
A map $X:\Omega \to \mathcal{X}$ is $\mathcal{F}/\mathcal{G}$-measurable if $X^{-1}(A) \in \mathcal{F}$ for all $A \in \mathcal{G}$.
Here, $\mathcal{G}$ _need not_ to be a $\sigma$-algebra.
If $X$ is $\mathcal{F}/\mathcal{G}$-measurable, then it is also $\mathcal{F}/\sigma(\mathcal{G})$-measurable, where $\sigma(\mathcal{G})$ is the smallest $\sigma$-algebra containing $\mathcal{G}$. 

Given a map $X:\Omega\to\mathcal{X}$ between measurable spaces $(\Omega, \mathcal{F})$ and $(\mathcal{X}, \mathcal{G})$, we define $$\sigma(X) = \{X^{-1}(A): A\in\mathcal{G}\}$$ to be the $\sigma$-algebra generated by $X$.
Here, the term "generated" means that $\sigma(X)$ is the _smallest_ $\sigma$-algebra containing $X^{-1}(A)$ for all $A \in \mathcal{G}$.
The map $X$ is $\mathcal{F}/\mathcal{G}$-measurable if and only if $\sigma(X) \subseteq \mathcal{F}$.
In fact, $\sigma(X)$ is a sub-$\sigma$-algebra of $\mathcal{F}$ and is also the smallest sub-$\sigma$-algebra for which $X$ is measurable.
Furthurmore, if $\mathcal{G} = \sigma(\mathcal{A})$ itself is generated by a set $\mathcal{A}\subseteq 2^{\mathcal{X}}$, it is enough to check that $$X^{-1}(\mathcal{A}) = \{X^{-1}(A) : A\in\mathcal{A}\}$$ is a subset of $\mathcal{F}$.

**(Borel $\sigma$-algebra)**
If $\mathcal{G}$ is a set of open intervals in $\mathbb{R}$, then the Borel $\sigma$-algebra $\mathcal{B}(\mathbb{R})$ is the smallest $\sigma$-algebra containing $\mathcal{G}$.

**(Random variable)**
A random variable on a measurable space $(\Omega, \mathcal{F})$ is a $\mathcal{F}/\mathcal{B}(\mathbb{R})$-measurable map $X:\Omega \to \mathbb{R}$. 



## 1. Law of large numbers

**(Convergence in probability)**
We say that $X_n$ converges to $X$ in probability if for every $\epsilon > 0$, $\lim_{n \to \infty} \Pr(|X_n - X| > \epsilon) = 0$, denoted by $X_n \overset{p}{\longrightarrow} X$.

**(Convergence in $L^r$)**
We say that $X_n$ converges to $X$ in $L^r$ if $\lim_{n \to \infty} \mathbb{E}(|X_n - X|^r) = 0$, denoted by $X_n \overset{L^r}{\longrightarrow} X$. 

**(Uncorrelated variables)**
Two random variables $X$ and $Y$ are uncorrelated if $\mathbb{E}(XY) = \mathbb{E}(X)\mathbb{E}(Y)$.

**(Lemma 1.1)**
Let $X_1, X_2, \ldots$ be a sequence of uncorrelated random variables with $\mathbb{E}(X_i) < \infty$, then we have that $\mathbb{V}(X_1 + \ldots + X_n) = \mathbb{V}(X_1) + \ldots + \mathbb{V}(X_n)$.

_Proof._ Omitted for brevity.

---
<p style="background-color: lightblue; padding: 10px;">
$\color{darkblue}{(\text{Theorem 1.1: $L^2$ weak law})}$
Let $X_1, X_2, \ldots$ be a sequence of uncorrelated random variables with $\mathbb{E}(X_i) = \mu$ and $\mathbb{V}(X_i) \le C < \infty$.
If $S_n := X_1 + \ldots + X_n$, then $S_n/n \overset{L^2}{\longrightarrow} \mu$.
</p>

_Proof._
We have that $\mathbb{E}[|S_n/n - \mu|^2] = \mathbb{V}(S_n/n) \le \frac{C/n}{n^2} \to 0$ as $n \to \infty$.
Here, we used Lemma 1.1 to compute the variance of $S_n/n$.

---
**(Chebyshev's inequality)**
For any random variable $X$ and $r > 0$, $\Pr(|X| \ge \epsilon) \le \epsilon^{-r}\mathbb{E}(|X|^r)$.

One small remark is that Chebyshev's inequality is generally not a sharp inequality (for example try bounding standard normal variables), however, it cannot be improved in [certain cases](https://en.wikipedia.org/wiki/Chebyshev%27s_inequality#Sharpness_of_bounds).

**(Lemma 1.2: Convergence in $L^r$ implies convergence in probability)**
For $r > 0$, if $Z_n \overset{L^r}{\longrightarrow} 0$, then $Z_n \overset{p}{\longrightarrow} 0$.

_Proof._ Since $\mathbb{E}(\|Z_n\|^r) \to 0$, the proof follows directly from Chebyshev's inequality applying to the random variable $Z_n$.

<p style="background-color: lightblue; padding: 10px;">
$\color{darkblue}{(\text{Theorem 1.2: Weak law of large numbers})}$
Let $X_1, X_2, \ldots$ be a sequence of uncorrelated random variables with $\mathbb{E}(X_i) = \mu$ and $\mathbb{V}(X_i) \le C < \infty$.
If $S_n := X_1 + \ldots + X_n$, then $S_n/n \overset{p}{\longrightarrow} \mu$.
</p>

_Proof._ Follows from Lemma 1.2 with $r = 2$ and the $L^2$ weak law.

If we relax the assumption of bounded variance, we can still obtain a weak law of large numbers with i.i.d assumption and a weaker variance assumption.

<p style="background-color: lightblue; padding: 10px;">
$\color{darkblue}{(\text{Theorem 1.3: Weak law of large numbers with relaxed variance assumption})}$
Let $X_1, X_2, \ldots$ be a sequence of i.i.d random variables with $x\cdot\Pr(|X_i| > x) \to 0$ as $x \to \infty$.
Let $\mu_n := \mathbb{E}[X_1\cdot\mathbb{I}\{|X_1| \le n\}]$.
Then, $S_n/n - \mu_n \overset{p}{\longrightarrow} 0$.
</p>

_Proof._ Omitted for brevity. 

<p style="background-color: lightblue; padding: 10px;">
$\color{darkblue}{(\text{Theorem 1.4: Weak law of large numbers for i.i.d random variables})}$
Let $X_1, X_2, \ldots$ be a sequence of i.i.d random variables with $\mathbb{E}[|X_1|] < \infty$.
Let $\mu := \mathbb{E}[X_1]$.
Then, $S_n/n \overset{p}{\longrightarrow} \mu$.
</p>

_Proof sketch._ Use theorem 1.3 and the dominated convergence theorem.

## 2. Borel-Cantelli lemmas (coming soon)
